%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
RRT-IRL whatever title we use.
}


\author{Noe perez$^{1}$ Kyriacos Shiarlis$^{2}$% <-this % stops a space
%\thanks{*This work was not supported by any organization}% <-this % stops a space
% \thanks{$^{1}$Albert Author is with Faculty of Electrical Engineering, Mathematics and Computer Science,
%         University of Twente, 7500 AE Enschede, The Netherlands
%         {\tt\small albert.author@papercept.net}}%
% \thanks{$^{2}$Bernard D. Researcheris with the Department of Electrical Engineering, Wright State University,
%         Dayton, OH 45435, USA
%         {\tt\small b.d.researcher@ieee.org}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Learning from Demonstration(LfD)\cite{argall2009survey} is a field that has recently drawn great interest from researchers and especially roboticists. This is because in many cases, being able to program a robot by demonstration saves tedious programming of complex behaviours by its designer. While most LfD methods consider supervised and unsupervised learning to fulfill their goals, certain approaches, namely Inverse Optimal Control (IOC) \cite{kalman1964linear} and Inverse Reinforcement Learning (IRL) \cite{abbeel2004apprenticeship} consider learning \emph{cost functions} from demonstration. These cost functions are then used to \emph{plan} the behaviour of the robot. Learning cost functions rather than a direct mapping from states to actions (i.e. policies) is an appealing concept because such representations tend to be more general and robust to changes in the environment. Take for example the case where the friction in the joints of a manipulator changes. A robot trained in a supervised manner has less chance of adapting and succeding than one that has been trained using IRL or IOC. In addition, cost functions are thought to be more succint \cite{abbeel2004apprenticeship} representations of the aims of the agent. Take for example an agent that whose aim is to get as fast as possible to a goal location. The policy for such an agent will be much harder to interpret when compared to its cost function. Despite their clear motivation, the aforementioned methods come with a certain cost. IRL for example requires modeling the task as a Markov Decision Process(MDP). However when it comes to robotics and especially path planning, MDPs are impractical. Firstly they place constraints on the model of the environment requiring it to be Markovian. Secondly, \emph{planning} in an MDP modelled environment is extremely costly, especially in continuous and potentially high dimentional domains such as the ones encountered in path planning. To make things worse, IRL typically requires solving such an MDP once per iteration. Thirdly, MDPs have no way of encoding important aspects of a robotic agent, such as kinodynamic constraints (or just can be exremelly difficult?). For this reason, a large portion of literature focusses on replacing the planning step in IRL with more convienient planners(I refer to these in the prior work). An early example of this is Maximum Margin Planning \cite{ratliff2006maximum}, where $A^*$ search was used instead of an MDP solver, allowing the method to be applied in a mobile robotics setting. The additional speed of such alternative planners does not only allow faster planning -and in effect learning- but allows a robot to \emph{replan} its trajectory, removing the need to represent every possible configuration of the environment in a model such as an MDP. When it comes to path planning, Rapidly Exploring Random Trees(RRT)\cite{lavalle1998rapidly} are extremely appealing due to their ability to plan quickly in relatively large configuration spaces while elegantly handling kinodynamic constraints. While many interesting variants of the RRT have been proposed, the most significant contribution is that of the RRT$^*$ algorithm \cite{karaman2011sampling}, where the original algorithm is extended to incorporate a cost function. This cost function directly affects the nature of the resulting plan and therefore behaves in a very similar manner to the cost functions that sit at the heart of methods such as IOC and IRL. While such a cost function is typically simple, aiming for example to find the closest path to a goal, different representations can be used to bring about more complex behaviours which are imperative if robots are to interact with humans on a daily basis.  In this paper, we present methods for effectively learning RRT$^*$ cost functions from demonstration. Our methods require no additional planner assumptions other than those inherent in RRT$^*$ making them particularly easy to implement. We begin by showing that the nature of the RRT$^*$ as a sample based planner requires somewhat different formulation of the learning problem. We go on to adress these issues and formulate algorithms that allow these cost functions to be learned in an appropriate manner. Finally we demonstrate the functionality of our methods and evaluate their performance on real and simulated data from a social navigation scenario. 




\section{Background}

\subsection{Related Work}

The main purpose of our work is to replace the typical planner used in IRL with one that is more convienient for robotic applications while retaining the main idea behind IRL, which is learning the underlying cost function to that planner using data from demonstrations.
This challenge has been tackled several times by researchers that seek to make IRL more applicable to real world situations such as those encountered in robotics. In \cite{ziebart2010modelingthesis} for example the Maximum Entropy IRL method developed in \cite{} was shown to work in domains of linear continouous dynamics with the optimal controller being a Linear-Quadratic Regulator(LQR). Since linear dynamics are hard to come by in robotics, in \cite{levine} local linear aproximations are considered. These bring about locally consistent rewards, and achieve good performance in a range of tasks that were previously too hard for MDPs. Other approaches to hte problem, use hybrid appriaches to planning. In Inverse Optimal Heuristic Control (IOHC) for example \cite{iohc} the authors model the long term goals of the agent as a coarse state MDP ensuring its tractability, at the same time as using supervised learning to determine the local policy of the agent at each state. Another example of a hybrid technique is that of Graph-Based IOC \cite{graphioc}. In this work the authors define discrete optimal control on a coarse graph and the actual path is executed using local trajectory optimisation techinques such as CHOMP \cite{chomp}, which would otherwise suffer from local minima. The method is shown to be effective in robotic manipulation where the number of degrees of freedom would otherwise pose problems for MDPs.


IRL, introduced in [], is the field whose very purpose is to extract cost functions from demonstrations. It is a predominantly iterative process, that can be split into 4 main stages.

\begin{itemize}
\item First item

\end{itemize}

 % Planning, is an essential step in this process because the performance of the learner's current reward function needs to be
 % assesed so that the appropriate update on can take place. Initially, the IRL problem was introduced as an MDP and therefore the planning step involved finding the optimal policy under different objectives[cite original],[max ent]. While the concept of learning cost functions was appealing, the costly planning procedure as well as the limited modeling capacity of MDPs limited the application of these methods to robotics.       


 % While there have been many important theoretical contributions to the field some are more relevant than others for this paper. Such a contribution is that of Maximum Margin Planning, where the ideas of IRL were first directly applied to mobile robot path planning. In other work, the ideas of IRL are applied to complex continuous domains, and used along side graph based algorithms[].


  Due to IRL's appealing properties, the robotics community was quick to adopt the concept and use it in many real world applications, with social navigation and compliance being one of the most noticable ones. A cost function that produces socially acceptable paths in different situations clearly satisfies the motivation behind Learning from Demonstration. It is very easy for us to socially navigate the environment, or even drive a robot through a crowd, but it is very hard to exactly determine the cost function we considered when eliciting that behaviour. The first application of IRL to crowd navigation can be found in \cite{henry_2010}, along with several contributions to the oribinal algorithm of Maximum Entropy Inverse Reinforcement Learning[\cite{ziebart2008maximum}. In [cite vasquez and aras] these ideas are enriched with new features as well as a software framework. Due to the complexity of the social navigation task and the aforementioned limitations of MDP's the authors employ frequent replanning as well as extensive use of parallel computation in order to achieve the task. Apart from crowd navigation, other work [cite wolfram] focusses on social compliance, extracting human intention, driving styles and route preferences. In fact most application of IRL to the real world have focused on modeling and/or replicating some aspect of human behaviour. 
  % Prior to IRL related approaches several contributions have been presented regarding the application of learning to the task of human-aware navigation: supervised learning is used in \cite{Trautman_2010} to learn appropriate human motion prediction models that take into account human-robot interaction when navigating in crowded scenarios. Unsupervised learning is used by Luber et al. \cite{luber_iros2012} to determine socially-normative motion prototypes, which are then employed to infer social costs when planning paths. In \cite{6696576}, a model based on social forces is employed. The parameters for the social forces are learnt from feedback provided by users.




\subsection{Preliminaries}


% Sampling based path planning algortihms such as Probabilistic Roadmaps(PRM) \cite{kavraki1996probabilistic} and Rapidly-Exploring-Random Trees(RRT)\cite{lavalle1998rapidly} have seen increasing popularity in various robotic planning applications, due to their ability to handle high dimentional continouous configuration spaces reliably and in reasonable time. In contrast to other planning and search algortihms such as A$^*$ and $D^*$, these algortihms do not require the specification of an admisible heuristic while sacrificing optimality for speed and state space coverage. While many interesting variants of the RRT have been invented such as the transition based RRT (T-RRT) \cite{jaillet2008transition}, by far the most significant contribution is that of the RRT$^*$ algorithm \cite{karaman2011sampling} where the original algorithm is extended to incorporate cost functions, based upon which an optimal path is guaranteed given an infinite amount of samples. These cost functions in essence determine the plan and as a result the behaviour of the robot in different situations, rendering their definition extremely important for roboticists.
% At times, rather than defining (and tuning) a cost function for a robot (or any other controled system) it is easier to demonstrate the desired plan or behaviour, and use algorithms to uncover the cost function that will bring about this behaviour. Examples of such methods lie in the fields of Inverse optimal control (IOC) and Inverse Reinforcement Learning (IRL)\cite{abbeel2004apprenticeship}, which due to their aforementioned property have been subject to increasing attention as well as success. A arguement for learning cost functions,
% rather than direct mappings to actions in a supervised manner [cite survey] is generality. In particular
% because cost functions are defined prior to planning, the policy of the agent(or robot) will differ if the
% environment (dynamics etc) changes while a policy learned by supervision will need to be revised. 

% Despite the appeal for learning planner cost functions, to our knowledge, there has been no known work that allows the learning of cost functions for RRT* planners (and its many derivatives [cite informed rrt]). This is exactly the contribution of this paper. 

% One application where RRTs are widely used is mobile robot navigation. At the same time, as robots enter public spaces, the environments in which robots are called to navigate have become increasingly complex[] and unpredictable. This means that a mobile robot's navigation cost function needs to be tediously tuned, in order to keep up with the task. An algorithm that can learn such a cost function from demonstration, without the need to change the planner would be a powerful tool in the arms of a roboticist.

%  % An essential assumption of these methods is that the planner used in the learning step of the algorithm must be used when planning under the learned cost function, otherwise the observed behaviour will not be compatible with the observations.
% Complex mobile robotics tasks, such as navigation are typically not modelled as control problems because of their computational complexity. Furthermore, modelling path planning as a Markov Decision Process (MDP) is usually avoided also due to its computational cost, with the exception of the case where this MDP is deterministic, which yields the same open loop policy as A$^*$. Therefore, even if our world was deterministic we would still be limited by the drawacks of A$^*$ planning from which probabilistic methods dont.\\

% It should be apparent that an algortihm that uses RRT$^*$ to learn as well as plan, would be of great value to roboticists seeking to incorporate human demonstrations into the design of their robots.

\section{PROCEDURE FOR PAPER SUBMISSION}

\subsection{Selecting a Template (Heading 2)}

First, confirm that you have the correct template for your paper size. This template has been tailored for output on the US-letter paper size. 
It may be used for A4 paper size if the paper size setting is suitably modified.

\subsection{Maintaining the Integrity of the Specifications}

The template is used to format your paper and style the text. All margins, column widths, line spaces, and text fonts are prescribed; please do not alter them. You may note peculiarities. For example, the head margin in this template measures proportionately more than is customary. This measurement and others are deliberate, using specifications that anticipate your paper as one part of the entire proceedings, and not as an independent document. Please do not revise any of the current designations

\section{MATH}

Before you begin to format your paper, first write and save the content as a separate text file. Keep your text and graphic files separate until after the text has been formatted and styled. Do not use hard tabs, and limit use of hard returns to only one return at the end of a paragraph. Do not add any kind of pagination anywhere in the paper. Do not number text heads-the template will do that for you.

Finally, complete content and organizational editing before formatting. Please take note of the following items when proofreading spelling and grammar:

\subsection{Abbreviations and Acronyms} Define abbreviations and acronyms the first time they are used in the text, even after they have been defined in the abstract. Abbreviations such as IEEE, SI, MKS, CGS, sc, dc, and rms do not have to be defined. Do not use abbreviations in the title or heads unless they are unavoidable.

\subsection{Units}

\begin{itemize}

\item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as Ò3.5-inch disk driveÓ.
\item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
\item Do not mix complete spellings and abbreviations of units: ÒWb/m2Ó or Òwebers per square meterÓ, not Òwebers/m2Ó.  Spell out units when they appear in text: Ò. . . a few henriesÓ, not Ò. . . a few HÓ.
\item Use a zero before decimal points: Ò0.25Ó, not Ò.25Ó. Use Òcm3Ó, not ÒccÓ. (bullet list)

\end{itemize}


\subsection{Equations}

The equations are an exception to the prescribed specifications of this template. You will need to determine whether or not your equation should be typed using either the Times New Roman or the Symbol font (please no other font). To create multileveled equations, it may be necessary to treat the equation as a graphic and insert it into the text after your paper is styled. Number equations consecutively. Equation numbers, within parentheses, are to position flush right, as in (1), using a right tab stop. To make your equations more compact, you may use the solidus ( / ), the exp function, or appropriate exponents. Italicize Roman symbols for quantities and variables, but not Greek symbols. Use a long dash rather than a hyphen for a minus sign. Punctuate equations with commas or periods when they are part of a sentence, as in

$$
\alpha + \beta = \chi \eqno{(1)}
$$

Note that the equation is centered using a center tab stop. Be sure that the symbols in your equation have been defined before or immediately following the equation. Use Ò(1)Ó, not ÒEq. (1)Ó or Òequation (1)Ó, except at the beginning of a sentence: ÒEquation (1) is . . .Ó

\subsection{Some Common Mistakes}
\begin{itemize}


\item The word ÒdataÓ is plural, not singular.
\item The subscript for the permeability of vacuum ?0, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ÒoÓ.
\item In American English, commas, semi-/colons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
\item A graph within a graph is an ÒinsetÓ, not an ÒinsertÓ. The word alternatively is preferred to the word ÒalternatelyÓ (unless you really mean something that alternates).
\item Do not use the word ÒessentiallyÓ to mean ÒapproximatelyÓ or ÒeffectivelyÓ.
\item In your paper title, if the words Òthat usesÓ can accurately replace the word ÒusingÓ, capitalize the ÒuÓ; if not, keep using lower-cased.
\item Be aware of the different meanings of the homophones ÒaffectÓ and ÒeffectÓ, ÒcomplementÓ and ÒcomplimentÓ, ÒdiscreetÓ and ÒdiscreteÓ, ÒprincipalÓ and ÒprincipleÓ.
\item Do not confuse ÒimplyÓ and ÒinferÓ.
\item The prefix ÒnonÓ is not a word; it should be joined to the word it modifies, usually without a hyphen.
\item There is no period after the ÒetÓ in the Latin abbreviation Òet al.Ó.
\item The abbreviation Òi.e.Ó means Òthat isÓ, and the abbreviation Òe.g.Ó means Òfor exampleÓ.

\end{itemize}


\section{USING THE TEMPLATE}

Use this sample document as your LaTeX source file to create your document. Save this file as {\bf root.tex}. You have to make sure to use the cls file that came with this distribution. If you use a different style file, you cannot expect to get required margins. Note also that when you are creating your out PDF file, the source file is only part of the equation. {\it Your \TeX\ $\rightarrow$ PDF filter determines the output file size. Even if you make all the specifications to output a letter file in the source - if your filter is set to produce A4, you will only get A4 output. }

It is impossible to account for all possible situation, one would encounter using \TeX. If you are using multiple \TeX\ files you must make sure that the rsion tool.

\subsection{Headings, etc}

Text heads organize the topics on a relational, hierarchical basis. For example, the paper title is the primary text head because all subsequent material relates and elaborates on this one topic. If there are two or more sub-topics, the next level head (uppercase Roman numerals) should be used and, conversely, if there are not at least two sub-topics, then no subheads should be introduced. Styles named ÒHeading 1Ó, ÒHeading 2Ó, ÒHeading 3Ó, and ÒHeading 4Ó are prescribed.

\subsection{Figures and Tables}

Positioning Figures and Tables: Place figures and tables at the top and bottom of columns. Avoid placing them in the middle of columns. Large figures and tables may span across both columns. Figure captions should be below the figures; table heads should appear above the tables. Insert figures and tables after they are cited in the text. Use the abbreviation ÒFig. 1Ó, even at the beginning of a sentence.

\begin{table}[h]
\caption{An Example of a Table}
\label{table_example}
\begin{center}
\begin{tabular}{|c||c|}
\hline
One & Two\\
\hline
Three & Four\\
\hline
\end{tabular}
\end{center}
\end{table}


   \begin{figure}[thpb]
      \centering
      \framebox{\parbox{3in}{We suggest that you use a text box to insert a graphic (which is ideally a 300 dpi TIFF or EPS file, with all fonts embedded) because, in an document, this method is somewhat more stable than directly inserting a picture.
}}
      %\includegraphics[scale=1.0]{figurefile}
      \caption{Inductance of oscillation winding on amorphous
       magnetic core versus DC bias magnetic field}
      \label{figurelabel}
   \end{figure}
   

Figure Labels: Use 8 point Times New Roman for Figure labels. Use words rather than symbols or abbreviations when writing Figure axis labels to avoid confusing the reader. As an example, write the quantity ÒMagnetizationÓ, or ÒMagnetization, MÓ, not just ÒMÓ. If including units in the label, present them within parentheses. Do not label axes only with units. In the example, write ÒMagnetization (A/m)Ó or ÒMagnetization {A[m(1)]}Ó, not just ÒA/mÓ. Do not label axes with a ratio of quantities and units. For example, write ÒTemperature (K)Ó, not ÒTemperature/K.Ó

\section{CONCLUSIONS}

A conclusion section is not required. Although a conclusion may review the main points of the paper, do not replicate the abstract as the conclusion. A conclusion might elaborate on the importance of the work or suggest applications and extensions. 

\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{APPENDIX}

Appendixes should appear before the acknowledgment.

\section*{ACKNOWLEDGMENT}

The preferred spelling of the word ÒacknowledgmentÓ in America is without an ÒeÓ after the ÒgÓ. Avoid the stilted expression, ÒOne of us (R. B. G.) thanks . . .Ó  Instead, try ÒR. B. G. thanksÓ. Put sponsor acknowledgments in the unnumbered footnote on the first page.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

References are important to the reader; therefore, each citation must be complete and correct. If at all possible, references should be commonly available publications.


\bibliographystyle{IEEEtran}
\bibliography{references}



\end{document}
